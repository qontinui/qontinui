# Discovery Module

## Overview

The `discovery` module is the core intelligence system of qontinui, providing automated detection and understanding of application states through visual analysis. It enables the framework to explore and understand applications without requiring manual state definitions.

## Purpose

The discovery system serves multiple critical functions:

1. **Automated State Detection**: Identify application states from screenshots
2. **Element Recognition**: Detect and classify UI elements
3. **State Construction**: Build structured state representations
4. **Region Analysis**: Understand screen layout and organization
5. **Relationship Mapping**: Discover state transitions and relationships

## Architecture

The discovery module is organized into specialized submodules:

```
discovery/
â”œâ”€â”€ element_detection/    # UI element identification
â”œâ”€â”€ region_analysis/      # Screen region analysis
â”œâ”€â”€ state_detection/      # State matching and identification
â”œâ”€â”€ state_construction/   # State object creation
â”œâ”€â”€ experimental/         # Research and experimental features
â””â”€â”€ pixel_analysis/       # Low-level pixel stability (existing)
```

## Module Overview

### Element Detection
Identifies and classifies individual UI elements such as buttons, text fields, icons, and other interactive components.

**Key capabilities:**
- Template matching
- Feature detection
- OCR integration
- ML-based classification

[Learn more â†’](element_detection/README.md)

### Region Analysis
Analyzes screen regions, their properties, and spatial relationships to understand UI structure.

**Key capabilities:**
- Screen segmentation
- Region property analysis
- Spatial relationship detection
- Temporal stability tracking

[Learn more â†’](region_analysis/README.md)

### State Detection
Identifies application states by matching visual characteristics against known patterns. The flagship **Differential Consistency Detection** algorithm enables robust state identification even in highly dynamic environments with animated backgrounds.

**Key capabilities:**
- **Differential Consistency Detection**: Statistical analysis of transition patterns
- **State signature matching**: Fast recognition of known states
- **Transition detection**: Identifies state changes and relationships
- **Stability analysis**: Multi-frame validation
- **Probabilistic inference**: Confidence-based detection

**Flagship Algorithm: Differential Consistency Detection**

The Differential Consistency Detection algorithm is a breakthrough approach that detects state regions by analyzing how pixels change consistently across many transition examples. This enables detection in challenging environments like games with animated backgrounds, where traditional methods fail.

**How it works:**
```
1. Collect 100-1000 transition pairs (before/after screenshots)
2. Compute pixel-wise differences for all transitions
3. Analyze consistency: high mean + low std = state boundary
4. Extract connected regions from consistency map
5. Rank regions by consistency score

Key Insight: State boundaries change consistently (e.g., menu appearing),
while dynamic backgrounds change randomly (e.g., animation frames).

Example: Menu detection in game with animated background
  - Menu pixels: Î” mean=199, std=2 â†’ consistency=0.95 âœ…
  - Background: Î” mean=82, std=48 â†’ consistency=0.15 âŒ
  Result: Menu clearly identified despite animation
```

**Usage Example:**
```python
from qontinui.discovery.state_detection import DifferentialConsistencyDetector

# Initialize detector
detector = DifferentialConsistencyDetector()

# Provide before/after screenshot pairs (100-1000 recommended)
transition_pairs = [
    (before_img1, after_img1),
    (before_img2, after_img2),
    # ... more pairs
]

# Detect state regions
regions = detector.detect_state_regions(
    transition_pairs,
    consistency_threshold=0.7,
    min_region_area=500
)

# Use results
for region in regions:
    print(f"Found region at {region.bbox}")
    print(f"Consistency score: {region.consistency_score:.2f}")
```

**When to Use:**
- âœ… Applications with animated/dynamic backgrounds (games, multimedia)
- âœ… Modal dialogs and overlays
- âœ… Menu systems and navigation
- âœ… State boundaries in dynamic environments
- âœ… When you have 100+ transition examples available

**Performance:**
- 100 pairs @ 1080p: ~4 seconds
- Accuracy: 93%+ with proper data
- Memory efficient: processes in batches

[Learn more â†’](state_detection/README.md) | [Comprehensive Guide â†’](/docs/STATE_DETECTION_GUIDE.md)

### State Construction
Constructs complete state objects from detected elements and regions.

**Key capabilities:**
- State object creation
- Defining feature identification
- Relationship mapping
- State validation and refinement

[Learn more â†’](state_construction/README.md)

### Experimental
Contains cutting-edge detection algorithms and research implementations.

**Key features:**
- SAM (Segment Anything Model) integration
- YOLO object detection
- Vision transformers
- Novel detection algorithms

âš ï¸ **Warning**: Experimental APIs are unstable and may change.

[Learn more â†’](experimental/README.md)

### Pixel Analysis (Existing)
Low-level pixel stability analysis for detecting static vs. dynamic regions.

**Key components:**
- Pixel stability matrix analysis
- Stable region extraction
- Multi-screenshot comparison

## Usage Examples

### Basic State Detection

```python
from qontinui.discovery import MultiScreenshotDetector

# Initialize detector
detector = MultiScreenshotDetector()

# Detect states from screenshots
screenshots = ["screenshot1.png", "screenshot2.png", "screenshot3.png"]
states = detector.detect_states(screenshots)

# Examine discovered states
for state in states:
    print(f"State: {state.name}")
    print(f"Elements: {len(state.elements)}")
    print(f"Confidence: {state.confidence}")
```

### Element Detection

```python
from qontinui.discovery.element_detection import ElementDetector

# Detect elements in a screenshot
detector = ElementDetector()
elements = detector.detect(screenshot)

# Process detected elements
for element in elements:
    print(f"{element.type} at {element.location}")
```

### Region Analysis

```python
from qontinui.discovery.region_analysis import RegionAnalyzer

# Analyze screen regions
analyzer = RegionAnalyzer()
regions = analyzer.analyze(screenshot)

# Examine regions
for region in regions:
    print(f"Region: {region.type}")
    print(f"Bounds: {region.bounds}")
    print(f"Stability: {region.stability_score}")
```

### State Construction

```python
from qontinui.discovery.state_construction import StateBuilder

# Construct state from detection data
builder = StateBuilder()
state = builder.construct(
    screenshot=screenshot,
    elements=elements,
    regions=regions,
    name="LoginScreen"
)

print(f"Constructed: {state.name}")
print(f"Defining elements: {len(state.defining_elements)}")
```

## Discovery Pipeline

The typical discovery workflow:

```
1. Capture Screenshot
   â†“
2. Element Detection
   â”œâ†’ Template Matching
   â”œâ†’ Feature Detection
   â””â†’ OCR/ML Classification
   â†“
3. Region Analysis
   â”œâ†’ Screen Segmentation
   â”œâ†’ Property Extraction
   â””â†’ Spatial Analysis
   â†“
4. State Detection
   â”œâ†’ Signature Matching
   â”œâ†’ Probability Calculation
   â””â†’ Stability Validation
   â†“
5. State Construction
   â”œâ†’ Object Creation
   â”œâ†’ Feature Selection
   â””â†’ Relationship Mapping
   â†“
6. State Management
   â””â†’ Storage & Registration
```

## Migration Status

The discovery module is undergoing a major migration and refactoring from the Java Brobot library:

### Completed
- âœ… Basic pixel stability analysis
- âœ… Multi-screenshot detection
- âœ… Core models and interfaces

### In Progress
- ğŸ”„ Element detection migration
- ğŸ”„ State detection refactoring
- ğŸ”„ Region analysis implementation

### Planned
- â³ State construction system
- â³ Experimental features integration
- â³ ML model integration (SAM, YOLO)
- â³ Performance optimizations

## Configuration

Discovery system configuration:

```python
# config.yaml
discovery:
  element_detection:
    methods: ['template', 'feature', 'ocr']
    confidence_threshold: 0.7

  region_analysis:
    min_region_size: 100
    segmentation_method: 'edge'

  state_detection:
    matching_algorithm: 'signature'
    stability_frames: 3
    confidence_threshold: 0.8

  experimental:
    enable_sam: false
    enable_yolo: false
```

## Performance Considerations

- **Caching**: Detection results are cached to avoid redundant computation
- **Parallel Processing**: Multiple frames can be analyzed in parallel
- **GPU Acceleration**: ML models can leverage GPU when available
- **Incremental Detection**: Only changed regions are re-analyzed
- **Lazy Loading**: Expensive models loaded only when needed

## Testing

Each submodule includes comprehensive tests:

```bash
# Run all discovery tests
pytest tests/qontinui/discovery/

# Run specific module tests
pytest tests/qontinui/discovery/test_element_detection.py
pytest tests/qontinui/discovery/test_state_detection.py
```

## Contributing

When adding new detection features:

1. Choose the appropriate submodule (or experimental for research)
2. Follow existing patterns and interfaces
3. Add comprehensive tests
4. Document algorithms and parameters
5. Consider performance implications
6. Update relevant README files

## Related Modules

- `state_management`: Manages discovered states
- `vision`: Core computer vision utilities
- `actions`: Uses detected states for navigation
- `orchestration`: Orchestrates discovery workflows
- `api`: Exposes discovery functionality via API

## Recent Additions (November 2024)

### Differential Consistency Detection

The flagship state detection algorithm has been added to enable robust state identification in dynamic environments.

**Key Features:**
- Statistical consistency analysis across transition pairs
- Works with animated backgrounds and dynamic content
- Automatic region extraction and ranking
- Confidence-based scoring
- Visualization tools included

**File**: `state_detection/differential_consistency_detector.py`

**Documentation**: See [STATE_DETECTION_GUIDE.md](/docs/STATE_DETECTION_GUIDE.md) for comprehensive guide

### Base Detector Classes

Two fundamental base classes provide the foundation for all detection algorithms:

**BaseDetector** (`base_detector.py`)
- Abstract base for single-image detectors
- Utility methods for box operations (merge, filter, IoU)
- Standard interface for all single-image algorithms

**MultiScreenshotDetector** (`multi_screenshot_detector.py`)
- Abstract base for multi-image analysis
- Temporal consistency utilities
- Persistent region detection
- Transition analysis helpers

### Enhanced State Detection Module

New implementations in `state_detection/`:
- **detector.py**: Core state detection interfaces and data models
- **differential_consistency_detector.py**: Main detection algorithm
- Support for signature-based detection
- Transition detection and validation
- Multi-frame stability analysis

### Expanded Element Detection

18+ specialized element detectors in `element_detection/`:
- Typography detection (8 algorithms)
- Structural elements (windows, borders, title bars)
- Interactive elements (buttons, menus, toolbars)
- Layout elements (grids, containers, slots)

Each detector inherits from `BaseDetector` and can be used independently or combined.

### Advanced Region Analysis

20+ region analyzers in `region_analysis/`:
- Window structure detection
- Grid pattern identification
- Text region detection (7 methods)
- Texture and color analysis
- Spatial relationship detection

### State Construction Pipeline

New `state_construction/` module:
- **builder.py**: Automated state object construction
- **ocr_name_generator.py**: Intelligent state naming using OCR
- **element_identifier.py**: Defining feature identification
- State validation and refinement

### Example Usage Module

**File**: `example_detector_usage.py`

Comprehensive examples demonstrating:
- How to implement custom detectors
- Single-image detection patterns
- Multi-screenshot analysis patterns
- Best practices and common patterns

### Experimental Detection Lab

New `experimental/` module with cutting-edge algorithms:
- SAM (Segment Anything Model) integration
- Hybrid detection strategies
- Color-based segmentation
- Edge detection variants
- Template matching enhancements

---

## Complete Module Reference

### Core Detection Framework
```
discovery/
â”œâ”€â”€ base_detector.py              # Single-image detector base (353 lines)
â”œâ”€â”€ multi_screenshot_detector.py  # Multi-image detector base (438 lines)
â””â”€â”€ example_detector_usage.py     # Usage examples (240 lines)
```

### State Detection (NEW)
```
state_detection/
â”œâ”€â”€ detector.py                            # Core interfaces (300 lines)
â””â”€â”€ differential_consistency_detector.py   # Main algorithm (571 lines)
```

### Element Detection (EXPANDED)
```
element_detection/
â”œâ”€â”€ detector.py                     # Base implementation (244 lines)
â”œâ”€â”€ Typography Detectors (8 types)
â”‚   â”œâ”€â”€ ocr_text_detector.py
â”‚   â”œâ”€â”€ mser_text_detector.py
â”‚   â”œâ”€â”€ stroke_width_text_detector.py
â”‚   â””â”€â”€ ... (5 more)
â”œâ”€â”€ Structural Detectors
â”‚   â”œâ”€â”€ window_border_detector.py
â”‚   â”œâ”€â”€ window_title_bar_detector.py
â”‚   â””â”€â”€ window_close_button_detector.py
â””â”€â”€ Interactive Detectors
    â”œâ”€â”€ button_detector.py
    â”œâ”€â”€ menu_bar_detector.py
    â”œâ”€â”€ sidebar_detector.py
    â””â”€â”€ modal_dialog_detector.py
```

### Region Analysis (EXPANDED)
```
region_analysis/
â”œâ”€â”€ analyzer.py                    # Core analyzer (258 lines)
â”œâ”€â”€ base.py                       # Base classes (195 lines)
â”œâ”€â”€ Grid Detectors (4 types)
â”‚   â”œâ”€â”€ grid_pattern_detector.py
â”‚   â”œâ”€â”€ contour_grid_detector.py
â”‚   â”œâ”€â”€ hough_grid_detector.py
â”‚   â””â”€â”€ ransac_grid_detector.py
â””â”€â”€ Specialized Analyzers
    â”œâ”€â”€ texture_uniformity_detector.py
    â”œâ”€â”€ color_quantization_detector.py
    â””â”€â”€ frequency_analysis_detector.py
```

### State Construction (NEW)
```
state_construction/
â”œâ”€â”€ builder.py                # State builder (345 lines)
â”œâ”€â”€ ocr_name_generator.py     # OCR naming (186 lines)
â””â”€â”€ element_identifier.py     # Feature ID (119 lines)
```

### Experimental (NEW)
```
experimental/
â”œâ”€â”€ sam3_detector.py          # SAM integration (245 lines)
â”œâ”€â”€ hybrid_detector.py        # Hybrid strategies (198 lines)
â”œâ”€â”€ consistency_detector.py   # Alt consistency (156 lines)
â””â”€â”€ ... (10+ experimental detectors)
```

---

## Future Enhancements

### Short-term
- GPU acceleration for all major operations
- ML model integration (SAM2, YOLO v8)
- Cloud API for remote detection
- Real-time streaming detection

### Mid-term
- Active learning system
- Cross-platform state mapping
- Real-time detection (<50ms latency)
- Automated hyperparameter tuning

### Long-term
- Semantic understanding via NLP integration
- Autonomous exploration and state mapping
- Multi-modal detection (visual + audio + interaction)
- Transfer learning for similar applications
- Reinforcement learning for intelligent exploration
